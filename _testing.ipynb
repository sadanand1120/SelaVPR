{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from easydict import EasyDict as edict\n",
    "import parser\n",
    "import os\n",
    "import network\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "args = edict({'brightness': None,\n",
    " 'cache_refresh_rate': 1000,\n",
    " 'contrast': None,\n",
    " 'criterion': 'triplet',\n",
    " 'dataset_name': 'st_lucia',\n",
    " 'datasets_folder': './datasets',\n",
    " 'dense_feature_map_size': [61, 61, 128],\n",
    " 'device': 'cuda',\n",
    " 'efficient_ram_testing': False,\n",
    " 'epochs_num': 50,\n",
    " 'features_dim': 1024,\n",
    " 'foundation_model_path': None,\n",
    " 'horizontal_flip': False,\n",
    " 'hue': None,\n",
    " 'infer_batch_size': 16,\n",
    " 'l2': 'before_pool',\n",
    " 'lr': 1e-05,\n",
    " 'majority_weight': 0.01,\n",
    " 'margin': 0.1,\n",
    " 'mining': 'partial',\n",
    " 'neg_samples_num': 1000,\n",
    " 'negs_num_per_query': 2,\n",
    " 'num_workers': 8,\n",
    " 'optim': 'adam',\n",
    " 'patience': 3,\n",
    " 'pca_dataset_folder': None,\n",
    " 'pca_dim': None,\n",
    " 'queries_per_epoch': 5000,\n",
    " 'rand_perspective': None,\n",
    " 'random_resized_crop': None,\n",
    " 'random_rotation': None,\n",
    " 'recall_values': [1, 5, 10, 20],\n",
    " 'registers': False,\n",
    " 'rerank_num': 100,\n",
    " 'resize': [224, 224],\n",
    " 'resume': 'ckpts/SelaVPR_msls.pth',\n",
    " 'saturation': None,\n",
    " 'save_dir': 'test/default/2025-02-06_13-22-01',\n",
    " 'seed': 0,\n",
    " 'test_method': 'hard_resize',\n",
    " 'train_batch_size': 4,\n",
    " 'train_positives_dist_threshold': 10,\n",
    " 'val_positive_dist_threshold': 25})\n",
    "model = network.GeoLocalizationNet(args)\n",
    "model = model.to(args.device)\n",
    "model = torch.nn.DataParallel(model)\n",
    "state_dict = torch.load(args.resume)[\"model_state_dict\"]\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpath = \"/robodata/smodak/VPR/SelaVPR/datasets/san_francisco/images/test/database/@0550313.87@4184192.09@10@S@037.80373@-122.42845@14666@00@089@003@@@@@.jpg\"\n",
    "img = Image.open(imgpath).convert('RGB')\n",
    "H, W = np.asarray(img).shape[:2]  # Original image dimensions\n",
    "img = t(img).unsqueeze(0).to(args.device)\n",
    "with torch.inference_mode():\n",
    "    fm = model.module.backbone(img)[\"x_norm_patchtokens\"]\n",
    "fm2 = fm.squeeze().reshape(16, 16, 1024)\n",
    "A = fm2.mean(dim=-1)\n",
    "A_resized = F.interpolate(A.unsqueeze(0).unsqueeze(0), size=(H, W), mode='bilinear', align_corners=False)\n",
    "A_resized = A_resized.squeeze().cpu().detach().numpy()\n",
    "A_resized = np.abs(A_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention_map(image, attention_map):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image)  # Display original image\n",
    "    im = ax.imshow(attention_map, cmap='jet', alpha=0.5)  # Overlay heatmap with transparency\n",
    "    ax.axis('off')\n",
    "    # Add colorbar\n",
    "    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.ax.tick_params(labelsize=8)  # Adjust colorbar label size for readability\n",
    "    plt.show()\n",
    "visualize_attention_map(Image.open(imgpath), A_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from match_image import *\n",
    "import os\n",
    "sela = SelaVPRminimal()\n",
    "img_dir = \"bags/route\"\n",
    "img_list = sorted(os.listdir(img_dir))\n",
    "img_paths = [os.path.join(img_dir, img) for img in img_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_index = 19\n",
    "candidate_indices = [3, 4, 5, 6, 7, 10, 20, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_imgpath = img_paths[query_index]\n",
    "candidate_imgpaths = [img_paths[i] for i in candidate_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = sela.match_image(query_imgpath, candidate_imgpaths)\n",
    "print([candidate_indices[i] for i in indices.squeeze().tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpr2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
